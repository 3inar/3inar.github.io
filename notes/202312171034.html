<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>./einar.sh : A large language model is a kind of web search</title>

  <meta name="description" content="Various writing, etc.">
  <meta name="author" content="Einar Holsbø">

  <script data-goatcounter="https://elleve.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>

  <link rel="stylesheet" href="/meta/main.css" />
  <link rel="stylesheet" href="/meta/syntax.css" />
</head>
<body>


<div class="menu">
  <a href="/">about</a>
  —
  <a href="/research/">research</a>
  —
  <a href="/talks/">talks</a>
  —
  <a href="/notes/">notes</a>
  —
  <a href="/links/">links</a>
  —
  <a href="/screenshot_garden/">screenshot garden</a>
  —
  <a href="/meta/"><em>meta</em></a>
</div>



<h1 id="a-large-language-model-is-a-kind-of-web-search">A large language
model is a kind of web search</h1>
<p>I saw this figure describing them as “solving real-world tasks,”
which I strongly disagree with. An LLM does not solve tasks any more
than the K&amp;R <em>C Programming Language</em> book makes C
programs.</p>
<p>If you want to write a function comparing two strings you can look it
up in K&amp;R and there is an example of such a function. Much the same
with the LLM robot: I write to the robot that I want a function
comparing two strings, and the robot shows me such a function. But the
LLM provides information on much more than K&amp;R. It also lies much
more than K&amp;R.</p>
<p>To me, the LLM is basically a lossy compression of the internet (or
whatever it was trained on) in which look up information by an
interactive conversational interface. You had to trade some accuracy to
get this interface. You also had to trade away the context and lineage
of whatever you looked up in this compressed internet. This is a big
problem because <a
href="https://buttondown.email/maiht3k/archive/information-is-relational/">Information
is relational</a>.</p>




<small>this file last touched 2024.05.29</small></body>
</html>
