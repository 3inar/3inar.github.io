<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>./einar.sh : Variance in the direction of a vector</title>

  <meta name="description" content="Various writing, etc.">
  <meta name="author" content="Einar Holsbø">

  <script data-goatcounter="https://elleve.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>

  <link rel="stylesheet" href="/meta/main.css" />
  <link rel="stylesheet" href="/meta/syntax.css" />
</head>
<body>


<div class="menu">
  <a href="/">about</a>
  —
  <a href="/research/">research</a>
  —
  <a href="/talks/">talks</a>
  —
  <a href="/notes/">notes</a>
  —
  <a href="/links/">links</a>
  —
  <a href="/meta/"><em>meta</em></a>
</div>



<h1 id="variance-in-the-direction-of-a-vector">Variance in the direction
of a vector</h1>
<p><strong>Status: half-baked</strong></p>
<p>This all is true in any number of dimensions, but let’s say we
measure two things for a bunch of people. Perhaps it is height and
weight, who knows. A measurement is then a vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mo stretchy="false" form="prefix">(</mo><mi>h</mi><mo>,</mo><mi>w</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x = (h, w)</annotation></semantics></math>.
If we have many measurements we can put them in a matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false" form="prefix">(</mo><msub><mi>x</mi><mn>1</mn></msub><mi>…</mi><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">X = (x_1 \ldots x_n)</annotation></semantics></math>.</p>
<p><img src="img/20240122_centering.png" style="width:90.0%" /></p>
<p>Suppose we center these data by subtracting the average vector from
each individual vector so that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover><mi>x</mi><mo accent="true">̃</mo></mover><mi>i</mi></msub><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">\tilde x_i = x_i - m</annotation></semantics></math>,
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>=</mo><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">m = \frac{1}{n} \sum x_i</annotation></semantics></math>
being the average. The total variance in these data is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><mo>∑</mo><msup><mrow><mo stretchy="true" form="prefix">‖</mo><msub><mover><mi>x</mi><mo accent="true">̃</mo></mover><mi>i</mi></msub><mo stretchy="true" form="postfix">‖</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{1}{n} \sum \lVert \tilde x_i\rVert^2</annotation></semantics></math>,
the average squared length of the centered vectors.</p>
<p><img src="img/20240122_variance_along.png" style="width:90.0%" /></p>
<p>The variance along a particular vector
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>v</mi><annotation encoding="application/x-tex">v</annotation></semantics></math>
is just the average squared length of your centered vectors if you
project them onto
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>v</mi><annotation encoding="application/x-tex">v</annotation></semantics></math>.</p>
<p>For any orthogonal basis
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub><mo>,</mo><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">v_1, v_2</annotation></semantics></math>
we can have
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mi>x</mi><mo accent="true">̃</mo></mover><mo>=</mo><mi>c</mi><msub><mi>v</mi><mn>1</mn></msub><mo>+</mo><mi>d</mi><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\tilde x = cv_1 + dv_2</annotation></semantics></math>
and because of Pythagoras we will have
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow><mo stretchy="true" form="prefix">‖</mo><mi>x</mi><mo stretchy="true" form="postfix">‖</mo></mrow><mn>2</mn></msup><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">‖</mo><mi>c</mi><msub><mi>v</mi><mn>1</mn></msub><mo stretchy="true" form="postfix">‖</mo></mrow><mn>2</mn></msup><mo>+</mo><msup><mrow><mo stretchy="true" form="prefix">‖</mo><mi>d</mi><msub><mi>v</mi><mn>2</mn></msub><mo stretchy="true" form="postfix">‖</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\lVert x \rVert^2 = \lVert cv_1 \rVert^2 + \lVert dv_2 \rVert^2</annotation></semantics></math>.
This means that we can always express the total variance as the sum of
variances in orthogonal directions.</p>
<p><img src="img/20240122_pythagoras.png" style="width:90.0%" /></p>




<small>this file last touched 2024.01.22</small></body>
</html>
