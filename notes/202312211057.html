<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>./einar.sh : Hallmarks of generative AI</title>

  <meta name="description" content="Various writing, etc.">
  <meta name="author" content="Einar Holsbø">

  <script data-goatcounter="https://elleve.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>

  <link rel="stylesheet" href="/meta/main.css" />
  <link rel="stylesheet" href="/meta/syntax.css" />
</head>
<body>


<div class="menu">
  <a href="/">about</a>
  —
  <a href="/research/">research</a>
  —
  <a href="/talks/">talks</a>
  —
  <a href="/notes/">notes</a>
  —
  <a href="/links/">links</a>
  —
  <a href="/screenshot_garden/">screenshot garden</a>
  —
  <a href="/meta/"><em>meta</em></a>
</div>



<h1 id="hallmarks-of-generative-ai">Hallmarks of generative AI</h1>
<p>Getting more and more exposed to your GPTs, chat and otherwise, your
midjourney illustrations, etc., etc., you start noticing some
things.</p>
<p>The text generator produces text that flows very well and in certain
ways is well-written, but it has a kind of flat alien voice.</p>
<p>The image generator makes images that look very polished but broadly
gives you a similar feeling of otherness. It is more striking here
because you can often immediately tell that someone has generated their
illustration by AI, but with text it’s more of a creeping feeling.</p>
<p>This is a (perhaps) growing list of signs that your friends, family,
colleagues, or students may be secretly using generative AI.</p>
<h2 id="unwarranted-use-of-superlatives">Unwarranted use of
superlatives</h2>
<p>Friend and colleague Marko pointed this out: Nobody uses the word
“pivotal,” but ChatGPT does so <em>constantly.</em> Even the most
mundane things are pivotal to ChatGPT. Probabilistically we express this
as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">h</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">G</mi><mi mathvariant="normal">P</mi><mi mathvariant="normal">T</mi></mrow><mo stretchy="false" form="prefix">|</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi></mrow><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mn>.99</mn></mrow><annotation encoding="application/x-tex">P(\mathrm{ChatGPT}|\mathrm{pivotal}) = .99</annotation></semantics></math>.</p>
<p>Many years ago someone described to me one of the local journalists
as “a man of many superlatives.” So also is ChatGPT.</p>
<h2 id="an-aggressive-lack-of-intentionality">An aggressive lack of
intentionality</h2>
<p>Images generated by AI often display a stricking lack of focus and
intentionality. I have enough to say about this that I put it in a
separate note: <a
href="/notes/202403071104.html">(202403071104)</a>.</p>
<p>In my limited experience this lack of focus/intentionality also
happens for text: it is very hard to make the AI stick to a coherent
whole for anything requiring more than a handful of paragraphs.</p>




<small>this file last touched 2024.03.07</small></body>
</html>
