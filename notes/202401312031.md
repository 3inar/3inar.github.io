# Lyngby Correspondent e03: of equal measure


## What's RNA-Seq even like?

I've been working on patching some holes in my understanding of RNA sequencing.
I worked with gene expression data in the last days of the microarray, so I
(used to) have some understanding of that technology, but RNA-Seq is a little
more mysterious to me. 

In a way I'm quite happy to take the more abstract "box of numbers" point of
view and focus on the 
[type of thing you can do with a box of numbers](https://en.wikipedia.org/wiki/Singular_value_decomposition) 
but I wanted to have an idea of what RNA-Seq data looks like, on average, for,
say, a certain type of bacterium. And you don't just download RNA-Seq data and
load it into R. There are all kinds of mysterious steps. The box of numbers
philosophy will only take you so far.

## Transformations
But I am not neglecting the box of numbers. I've been looking at
@greenacre_2023, a kind of spicy preprint on transformation approaches to
compositional data. Remember that compositions sum to some constant: we grabbed
five marbles and three of them were blue so we know how many reds there are.
There are two types of marble but only one degree of freedom: all of the data
lie on the line described by 
$\text{reds} + \text{blues} = 5$ 
and the only information we can gain is relative. There are three blue marbles
for every two red ones. How many in total? Nobody knows.

A widely-used approach is to lean into this and consider logarithmic ratios
(logratios) like 
$\log \frac{\text{blues}}{\text{reds}}$, 
where this particular one is called an additive logratio. This puts the data in
an unconstrained space, and considering ratios gets us out of some problems
with coherence: If I analyze compositions of the form $(x, y, z)$ and consider
the ratio $x/y$ I will reach the same conclusions as you do if you only
consider the _subcomposition_ $(x, y)$, no matter how each of us normalizes the
vector.

But the additive logratio transformation is considered crude because it's not
an isometry: it doesn't preserve distances. To not preserve distances is to
distort the data, so you'd ideally like to have an isometry. An example of a
linear isometry is rotation by $\theta$ degrees. A triangle is mathematically
the same triangle if you turn it on its head. It isn't if you stretch it.

![](img/20240201_isometry.png){ width=95% }

The centered logratio transformation preserves distances. Here instead of
dividing by a certain element of the vector you divide by the geometric mean of
the vector. But the resulting coordinates depend on the entire vector so we
still have to consider ratios of the sort 
$\frac{x/gm(x,y)}{y/gm(x,y)} = \frac{x}{y}$ 
to get the subcompositional coherence we had earlier. So various other, more
complicated transformations were conceived, and since they are more complicated
their interpretation is more subtle.

**Getting to the point (if any):** @greenacre_2023 is a spicy paper because they
argue that in high dimensions there are many transformations that are
near-isometries. This means we could just use the additive log ratio for
its simplicity and wouldn't be sacrificing much in terms of geometry. 

But even better: since dividing by zero or taking the logarithm of zero are
undefined, all logratio transformations have a zeros problem.  The
mathematicians are happy to just define this problem away, saying that this
whole theory of logratios, etc., is for strictly positive data. But that
doesn't help the data analyst. Zeros are pretty common in real data! Various
hacky solutions exist (like adding a small arbitrary constant); @greenacre_2023
opens the door for something like 
[Box–Cox](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation), 
which tolerates zeros and has the logarithm as a limiting case. 

## Bike news

The weather in Denmark is 5 degrees C, partially cloudy. Like a good summer day
back home, really. Conditions are now such that I can take an alternate bike
route through the forests, etc. It's pretty good, pretty scenic at times, but I
did end up with water up past my ankles at one point.

## Links
* [For high-dimensional data there is a certain sample size below which there is no correlation between true and estimated odds ratio.](https://hbiostat.org/bbr/hdata)
* [openalexR](https://docs.ropensci.org/openalexR/) is an R package to interface with [https://openalex.org](). See also 
* [The Ways folder](https://lrhodes.net/ways/ways.html):

  > Putting information that you’ve found useful on a simple web page with no
  > ads, no scripts, no ulterior motives—this is a valuable online service.
* [Mathoverflow Q](https://mathoverflow.net/questions/462766/is-there-a-fast-way-to-check-if-a-matrix-has-any-small-eigenvalues): is there a fast way to check if [millions of matrices have] any small eigenvalues? Yes: do it on the GPU.
