---
title: "Comparing a relative risk with an odds ratio"
author: "Einar"
date: 2018-04-22
description: "When is an odds ratio similar to a relative risk?"
tags: ["probability", "odds", "odds ratio", "relative risk"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev.args=list(bg="transparent"))
```

In connection with a meta analysis I helped with recently we wanted to compare
some relative risk results from another analysis with the odds ratios that came
from ours. This made me wonder to what extent the two measurements are
comparable. The short story is that they aren't generally comparable, but when
dealing with small probabilities they are quite similar. The long story follows
below.

## Definitions
Suppose we are comparing the probability of falling ill between two groups. People
who belong to group one have a $p_1$ probability of falling ill; people who belong
to group two have a $p_2$ probability of falling ill. The _relative risk_ between
the two groups is the ratio of the two probabilities $RR = p_1/p_2$, while the 
_odds ratio_ is the ratio of the odds in the two groups. The odds of some event that
has probability $p$ is $p/(1-p),$ so the odds ratio is $OR = \frac{p_1/(1-p_1)}{p_2/(1-p_2)} = \frac{p_1(1-p_2)}{p_2(1-p_1)}.$

## Exploratory analysis
As usual my first instinct is to simulate some numbers and see what happens. Below 
I generate pairs of probabilities uniformly on between 0 and 1 and plot the relationship 
between their ORs and RRs.
```{r}
# generate probabilities
probs1 <- runif(100000)
probs2 <- runif(100000)

# calculate RR and OR
RR <- probs1/probs2
OR <- (probs1/(1-probs1))/(probs2/(1-probs2))

plot(OR, RR, xlim=c(0,15), ylim=c(0,15), pch=20, col="grey", bty="n")
abline(0,1, col="black", lwd=2)
abline(1,0, col="black", lwd=2)
```

The plot shows OR-RR pairs for $(p_1, p_2)$ pairs. There is a black line
horizontally at RR=1, and a black line with zero intercept, unity slope. 
The general pattern here is fairly uninteresting. Focussing on the case 
where $p_1 > p_2:$ For a given RR the OR is always greater. This is
because $OR = RR\cdot\frac{1-p_2}{1-p_1},$ where $\frac{1-p_2}{1-p_1} \gt 1.$ it is the other way around when $p_2 > p_1$. Other than this there isn't much
reason to believe that we can compare these quantities if we know nothing else 
about them. What if we know that at least one of the probabilities is quite small?
Let's say less than 5%?

```{r}
one_small <- probs1 < .05 | probs2 < .05

plot(OR[one_small], RR[one_small], xlim=c(0,15), ylim=c(0,15), pch=20, 
     col="grey", bty="n", main="At least one probability < .05")
abline(0,1, col="black", lwd=2)
```

OK! This is pretty good, at least, say, below five. If we look at it the other way, 
and focus on the case where one probability is greater than 95% we are pretty
much guaranteed not to have comparable RR and OR.

```{r}
one_large <- probs1 > .95 | probs2 > .95

plot(OR[one_large], RR[one_large], xlim=c(0,15), ylim=c(0,15), pch=20, 
     col="grey", bty="n", main="At least one probability > .95")
abline(0,1, col="black", lwd=2)
```

So we should definitely be careful there. What if both probabilities are small
though?

```{r}
small <- probs1 < .05 & probs2 < .05

plot(OR[small], RR[small], xlim=c(0,15), ylim=c(0,15), pch=20, 
     col="grey", bty="n", main="Both probabilities < .05")
abline(0,1, col="black", lwd=2)
```

This is great! Dealing with rare events you can safely compare an odds ratio
with a relative risk. Incidentally we were dealing with some very small death
rates in our meta analysis and so a comparison should be possible. However we
got an odds ratio of 6 and the other analysis reported a relative risk of
somehting like 12, which as we saw is impossible if the base probabilities are
the same.

## What's special about small probabilities
We can rewrite the odds ratio once again to get $OR = \frac{p_1 - p_1p_2}{p_2 -
p_1p_2}$. Now if we let $p_1$ and $p_2$ approach zero, the term $p_1p_2$
approaches zero much faster and so $\frac{p_1 - p_1p_2}{p_2 - p_1p_2} \approx
\frac{p_1}{p_2}=RR.$ If we let $p_1 \to 1$ we get $\frac{p_1 - p_1p_2}{p_2 -
p_1p_2} \to \infty$. This explains both the low-probability figure and the
high-probability figure.



