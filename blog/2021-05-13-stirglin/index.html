<!DOCTYPE html>
<html lang="en-us">

<head>
  <title>Stirglin&#39;s approximation [sic] | Just data things</title>

  <meta charset="UTF-8">
  <meta name="language" content="en">
  <meta name="description" content="">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  
  
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Stirglin&#39;s approximation [sic]" />
  <meta name="twitter:description" content=""/>
  <meta name="twitter:site" content="https://twitter.com/0xeinar" />
  <meta name="twitter:creator" content="https://twitter.com/0xeinar" />
  

  <link rel="shortcut icon" type="image/png" href="/favicon.ico" />


  
  
    
 
  
  
  
  
  
  
    
    <link type="text/css" rel="stylesheet" href="/css/post.min.86d1effd4c412b85ac13db53a90c473a0f256f789b821e131125c9aa25cb6a6d.css" integrity="sha256-htHv/UxBK4WsE9tTqQxHOg8lb3ibgh4TESXJqiXLam0="/>
  
    
    <link type="text/css" rel="stylesheet" href="/css/custom.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css" integrity="sha256-47DEQpj8HBSa&#43;/TImW&#43;5JCeuQeRkm5NMpJWZG3hSuFU="/>
  
  
   
   
    

<script type="application/ld+json">
  
    {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/3inar.github.io\/"
      },
      "articleSection" : "blog",
      "name" : "Stirglin\u0027s approximation [sic]",
      "headline" : "Stirglin\u0027s approximation [sic]",
      "description" : "",
      "inLanguage" : "en-US",
      "author" : "",
      "creator" : "",
      "publisher": "",
      "accountablePerson" : "",
      "copyrightHolder" : "",
      "copyrightYear" : "2021",
      "datePublished": "2021-05-13 00:00:00 \u002b0000 UTC",
      "dateModified" : "2021-05-13 00:00:00 \u002b0000 UTC",
      "url" : "https:\/\/3inar.github.io\/blog\/2021-05-13-stirglin\/",
      "wordCount" : "1414",
      "keywords" : ["Blog"]
    }
  
  </script>
</head>

<body>
  <div class="burger__container">
  <div class="burger" aria-controls="navigation" aria-label="Menu">
    <div class="burger__meat burger__meat--1"></div>
    <div class="burger__meat burger__meat--2"></div>
    <div class="burger__meat burger__meat--3"></div>
  </div>
</div>
 

  <nav class="nav" id="navigation">
  <ul class="nav__list">
    
    
      <li>
        <a  href="/">about</a>
      </li>
    
      <li>
        <a  class="active"
         href="/blog">blog</a>
      </li>
    
      <li>
        <a  href="/research/">research</a>
      </li>
    
      <li>
        <a  href="/talks/">talks</a>
      </li>
    
  </ul>
</nav>


  <main>
    
    

    <div class="flex-wrapper">
      <div class="post__container">
        <div class="post">
          <header class="post__header">
            <h1 id="post__title">Stirglin&#39;s approximation [sic]</h1>
            <time datetime="2021-05-13 00:00:00 &#43;0000 UTC" class="post__date">May 13, 2021</time> 
          </header>
          <article class="post__content">
              

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>If you have read any introductory probability material, which I have lately, you have seen Stirling’s approximation to the factorial
<span class="math display">\[n! = n\cdot(n-1)\cdot(n-2)\cdot\ldots\cdot2\cdot1.\]</span>
It seems to be standard material and looks like
<span class="math display">\[
n! \approx n^ne^{-n}\sqrt{2\pi n} = \hat n!.
\]</span></p>
<p>I introduce the probably nonstandard <span class="math inline">\(\hat n!\)</span> as a shorthand for this approximation. At the intro to probability level <span class="math inline">\(\hat n!\)</span> is usually presented without comment. There are various proofs/derivations that show that for large <span class="math inline">\(n\)</span> the ratio <span class="math inline">\(\frac{\hat n!}{n!}\)</span> tends to unity, but they mostly look pretty tricky to me.</p>
<p>I saw a somewhat informal derivation in <em>The Art of Doing Science and Engineering</em> by Richard Hamming, which was quite understandable as far as it went. It went as far as
<span class="math display">\[
n! \approx Cn^ne^{-n}\sqrt n,
\]</span>
and then moved on, stating simply that <span class="math inline">\(C=\sqrt{2\pi}\)</span> is the approximation error as <span class="math inline">\(n\to\infty\)</span>.</p>
<p>The past few days I have been wondering whether I, an idiot by most accounts, could
have derived Stirling’s approximation (I couldn’t). And if not (see previous), how close could I get?</p>
<div id="stirglins-approximation" class="section level2">
<h2>Stirglin’s approximation</h2>
<p>The basic steps aren’t too bad. Usually when we have a huge product of things that
we would rather break up into smaller, possibly more tractable things, we take <span class="math inline">\(\log\)</span>s:
<span class="math display">\[
\log(n!) = \sum_{x=1}^n \log x.
\]</span>
Fine. Knowing that a sum is basically a bumpy integral I suppose it could make sense to say that
<span class="math display">\[
\sum_{x=1}^n \log x \approx \int_1^n \log x~\mathrm dx.
\]</span>
This is, after all, the Riemann sum of that integral with unit-size steps. The integral comes out as
<span class="math display">\[
\left. \int_1^n \log x~\mathrm dx = x\log x - x \right\rvert_1^n = n\log n -n + 1.
\]</span>
So that’s the approximation sorted. Simply undo the <span class="math inline">\(\log\)</span>s by taking the exponential and arrive at my latest invention, <strong>Stirglin’s approximation</strong>:<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
<span class="math display">\[
n! \stackrel{?}{\approx} n^n e^{-n}e = {{\hat n??}}.
\]</span>
Here I have expanded the standard notation for the factorial to include <a href="https://en.wikipedia.org/wiki/Chess_annotation_symbols">chess annotation</a>. At this point it’s usual to present a table of values for the factorial and the approximation. I’ll instead show a plot of <span class="math inline">\(\frac{\hat{n}!}{n!}\)</span> and
<span class="math inline">\(\frac{\hat n??}{n!}\)</span> for various <span class="math inline">\(n\)</span>. The horizontal line is <span class="math inline">\(1 = \frac{n!}{n!}\)</span>, the perfect approximation.</p>
<pre class="r"><code>stirling &lt;- function(n) {
  (n^n)*exp(-n)*sqrt(2*pi*n)
}

stirglin &lt;- function(n) {
  (n^n)*exp(1-n)
}</code></pre>
<p><img src="/blog/2021-05-13-stirglin_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Although <span class="math inline">\(\hat n ??\)</span> is exact for <span class="math inline">\(n=1\)</span> it seems less useful for larger <span class="math inline">\(n\)</span>. What do we do?</p>
</div>
<div id="stirglins-approximation-of-order-ii" class="section level2">
<h2>Stirglin’s approximation of order II</h2>
<p>We already know what’s wrong by inspecting <span class="math inline">\(\hat n!\)</span>. Thanks for the help Stirling; shoulders of giants and all that. The factor <span class="math inline">\(\sqrt{2\pi}\)</span> is not that important, it’s roughly the same as our factor <span class="math inline">\(e\)</span>: What’s crucially missing is the factor <span class="math inline">\(\sqrt n\)</span>.</p>
<p>Where does it come from though? Hamming observes in his derivation that the
trapezoidal rule approximation to an integral, which is more accurate than the Riemann sum, is
<span class="math display">\[
\begin{align}
\frac{1}{2} \log 1 + \sum_{x=2}^{n-1} \log x + \frac{1}{2}\log n &amp;\approx \int_1^n \log x~\mathrm dx \\&amp;= n\log n -n + 1.
\end{align}
\]</span>
Notice that <span class="math inline">\(\log 1 = 0,\)</span> so its coefficient doesn’t matter. Notice also that we’re missing half a <span class="math inline">\(\log n\)</span> to make up the sum we want; if we add this on both sides of the equation we get
<span class="math display">\[
\sum_{x=1}^n \log x \approx n \log n - n + 1 + \frac{1}{2}\log n.
\]</span>
This is the missing <span class="math inline">\(\sqrt n\)</span>. But I could not have known this beforehand, so let’s pretend we don’t.
I suppose I would have known about the existence of the trapezoid rule but I would not have thought about using it. I would have thought about doing computations and plots.</p>
<p>I don’t know much about Stirling but probably he did not have a 2018 MacBook Pro.
With this device it is not much work to multiply or sum a bunch of numbers, or even take <span class="math inline">\(\log\)</span>s. What opulence. It certainly isn’t hard for me to compare <span class="math inline">\(\sum_{x=1}^n \log x\)</span> with <span class="math inline">\(\log \hat n?? = n\log n -n + 1\)</span> up to a very large <span class="math inline">\(n\)</span> indeed.</p>
<p><img src="/blog/2021-05-13-stirglin_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Above I show the <span class="math inline">\(\log\)</span> error in <span class="math inline">\(\hat n??\)</span> all the way up to <span class="math inline">\(n=10^6\)</span>. The number <span class="math inline">\(10^6!\)</span> has <em>at the very least</em> four and a half millions digits.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> You’d never
want to look at that number itself, but you may want to use <span class="math inline">\(n!\)</span> or an easier-to-deal-with approximation
to derive other quantities (such as probabilities) supposing <span class="math inline">\(n\)</span> quite large.</p>
<p>What we’re looking for is a function of <span class="math inline">\(n\)</span> that we can multiply with <span class="math inline">\(\hat n??\)</span>
so that <span class="math inline">\(\frac{f(n)\hat n??}{n!} \approx 1\)</span> as <span class="math inline">\(n\)</span> increases.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Or, equivalently, we’re looking for a function that that we can subtract on the <span class="math inline">\(\log\)</span> scale to make the error zero. Then it’s just a matter of fitting the curve above.</p>
<p>It’s clear from the figure that the error is a non-linear function of <span class="math inline">\(n\)</span>. It would be nicest for the look of our approximation if the function could be made very simple. It would not be very satisfying with, say, a neural network function approximation.</p>
<p>In <em>Exploratory Data Analysis</em>, Tukey advocates trying a simple <a href="https://onlinestatbook.com/2/transformations/tukey.html">ladder of transformations</a>, fitting curves of the form <span class="math inline">\(y = \beta_0 + \beta_1 f(x)\)</span> with <span class="math inline">\(f(x)\)</span> climbing the ladder
<span class="math display">\[
\frac{1}{x^2}, \frac{1}{x}, \frac{1}{\sqrt{x}}, \log x, \sqrt x, x, x^2.
\]</span>
Our suspect is in this lineup, but we’re pretending to be me so we don’t know that. But we know that the curve is <em>bendy downard</em>, as they say in the
technical language, and so the rungs below <span class="math inline">\(x\)</span> are the transformations
likely to make the relationship less bendy. They all stretch out smaller numbers and pack larger numbers closer together, if you think about it.</p>
<p><img src="/blog/2021-05-13-stirglin_files/figure-html/unnamed-chunk-5-1.png" width="864" /></p>
<p>Look at that straight <span class="math inline">\(\log n\)</span> line. Majestic! If we fit this straight line so that we have <span class="math inline">\(\mathrm{error} \approx \beta_0 + \beta_1\log n\)</span>
we can simply subtract it to get an error <span class="math inline">\(\approx\)</span> zero.</p>
<pre class="r"><code>lm_fit = lm(ratio~log(Ns))
coef(lm_fit)</code></pre>
<pre><code>## (Intercept)     log(Ns) 
##  0.08096557 -0.49999261</code></pre>
<p>So we reckon <span class="math inline">\(\mathrm{error} \approx 0.08 - 0.5\log n\)</span> and are in a position to
formulate <strong>Stirglin’s approximation of order II</strong>:
<span class="math display">\[
\begin{align}
\log n! &amp;\approx \log \hat n!? \\
 &amp;= \log \hat n?? - (0.08 - 0.5\log n) \\
 &amp;= n\log n - n + 0.92 + 0.5\log n,\\
 \mathrm{and\ so,}\\
 \hat n!? &amp;= n^ne^{-n}e^{0.92}\sqrt n
\end{align}
\]</span></p>
<p>Notice that we also got slightly closer to the <span class="math inline">\(\sqrt{2\pi}\)</span> factor going from
<span class="math inline">\(e\)</span> to <span class="math inline">\(e^{0.92}\)</span> The new comparison plot looks as follows:</p>
<pre class="r"><code>stirglin_2 &lt;- function(n) {
  (n^n)*exp(.92-n)*sqrt(n)
}</code></pre>
<p><img src="/blog/2021-05-13-stirglin_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The slightly larger grey points show Stirling’s approximation for comparison.
We are very close! As with Stirling, Stirglin II looks good even for quite small
<span class="math inline">\(n\)</span>. Let’s look at the error for large <span class="math inline">\(n\)</span>. I will go from <span class="math inline">\(n=100\,000\)</span> to <span class="math inline">\(n=5\,000\,000\)</span>.</p>
<p><img src="/blog/2021-05-13-stirglin_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>We very slightly overestimate. For my money that’s as good as very slightly underestimating. I believe the jigglyness toward the higher <span class="math inline">\(n\)</span>s has to do with rounding error in floating point operations.</p>
<p>So empirically we get roughly what the theory dictates, which is always reassuring, but we’re pretending to not have the theory and to be too bad at maths to derive it. Stirglin’s second-order approximation gives us a decent approximation for quite large <span class="math inline">\(n\)</span>. If we need to know its error for an even larger but still reasonable <span class="math inline">\(n\)</span> we can always check. What we don’t get is guarantees about its behavior as <span class="math inline">\(n\to\infty\)</span>.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> In other words it’s quite accurate for applied work, but you can’t use it for proofs.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>I was thinking about doing a whole bit about Stirling’s less talented brother Stirglin, his manuscripts recently discovered in some attic, but it would have made this text insufferable.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Take everything above <span class="math inline">\(100\,000\)</span> as <span class="math inline">\(100\,000\)</span> exactly and drop what’s below for a smaller but easier-to-deal-with number. This will have <span class="math inline">\(\log_{10} 100\,000^{900\,000} = 900\,000\cdot5 = 4\,500\,000\)</span> digits.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>No point focussing on getting a good approximation for small <span class="math inline">\(n\)</span>, there we can just use <span class="math inline">\(n!\)</span> directly.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Because I don’t know how. But I can offer a consolation prize type guarantee: If you know that for some <span class="math inline">\(n - 1\)</span> the error is <span class="math inline">\(\mathrm{err}(n-1) = C - 0.5\log (n-1)\)</span> you can show by some algebra tricks (nothing crazy but tedious to type out in full) that the error for <span class="math inline">\(n\)</span> is <span class="math display">\[C - 0.5\log(n) - 1 + (n - 0.5)\log\frac{n}{n-1} \\ = \mathrm{err}(n) - 1 + (n - 0.5)\log\frac{n}{n-1}.\]</span> This last term goes toward unity quite quickly and it is the case that <span class="math inline">\(\lim_{n\to\infty} (n - 0.5)\log\frac{n}{n-1} = 1,\)</span> according to <a href="https://live.sympy.org/">SymPy</a>, which I used to check that limit. It’s not an ironbound proof or anything, but it’s promising.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>


              
                  

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
            showMathMenu: false, //disables context menu
            tex2jax: {
            inlineMath: [ ['$','$'], ['\\(','\\)'] ]
           }
    });
</script>
              
          </article>
          

<ul class="tags__list">
    
    
    </ul>

 <div class="pagination">
  
    <a class="pagination__item" href="https://3inar.github.io/blog/2020-12-11-lindley-book-rview/">
        <span class="pagination__label">Previous Post</span>
        <span class="pagination__title">This delightful book review</span>
    </a>
  

  
    <a class="pagination__item" href="https://3inar.github.io/blog/2021-06-01-bayes_fdr/">
      <span class="pagination__label">Next Post</span>
      <span class="pagination__title" >Note: Bayes false discovery rate</span>
    </a>
  
</div>

          
          <footer class="post__footer">
            


<div class="social-icons">
  
     
    
      <a
        class="social-icons__link"
        title="Twitter"
        href="https://twitter.com/0xeinar"
        target="_blank"
        rel="me noopener"
      >
        <div class="social-icons__icon" style="background-image: url('https://3inar.github.io/svg/twitter.svg')"></div>
      </a>
    
  
     
    
      <a
        class="social-icons__link"
        title="GitHub"
        href="https://github.com/3inar"
        target="_blank"
        rel="me noopener"
      >
        <div class="social-icons__icon" style="background-image: url('https://3inar.github.io/svg/github.svg')"></div>
      </a>
    
  
     
    
      <a
        class="social-icons__link"
        title="stackexchange"
        href="https://stats.stackexchange.com/users/43625/"
        target="_blank"
        rel="me noopener"
      >
        <div class="social-icons__icon" style="background-image: url('https://3inar.github.io/svg/stackexchange.svg')"></div>
      </a>
    
     
</div>

            <p>© 2022</p>
          </footer>
          </div>
      </div>
      
    </div>
    

  </main>

   

  
  <script src="/js/index.min.301a8b0870381bf76b3b5182e8966d363a0474281183439beb024d8b8228fc66.js" integrity="sha256-MBqLCHA4G/drO1GC6JZtNjoEdCgRg0Ob6wJNi4Io/GY=" crossorigin="anonymous"></script>
  
  
  <script src="https://unpkg.com/prismjs@1.20.0/components/prism-core.min.js"></script>

  
  <script src="https://unpkg.com/prismjs@1.20.0/plugins/autoloader/prism-autoloader.min.js"
    data-autoloader-path="https://unpkg.com/prismjs@1.20.0/components/"></script>

  


</body>

</html>
