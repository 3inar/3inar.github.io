<!DOCTYPE html>
<html lang="en-US">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="description" content="Academic web page">
<meta name="keywords" content="statistics,machine learning,research,computer science">

<base href="http://3inar.github.io/">

<title>Einar Holsbø</title>

<meta name="generator" content="Hugo 0.55.5" />




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400|Roboto+Slab:400,700|Roboto:300,300i,400,400i,500,500i,700,700i">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
<link rel="stylesheet" href="http://3inar.github.io/css/main.css">




<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="theme-color" content="#ffffff">

</head>
<body lang="en-US">
<div class="container">


<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



<header class="row text-left title">
  <h1 class="title">Understanding undersampling</h1>
</header>
<section id="category-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-left meta">
        PUBLISHED ON APR 9, 2017 
      
    </h6>
  </div>
  
</section>
<section id="content-pane" class="row">
  <div class="col-md-12 text-left content">
    


<p>I really like Frank Harrell’s blog. He writes all kinds of useful things, and as
I am working in the classification/predition area I was particularly interested
in his two posts about <a href="http://www.fharrell.com/2017/01/classification-vs-prediction.html">classification vs. prediction</a> and <a href="http://www.fharrell.com/2017/03/damage-caused-by-classification.html">improper scoring rules</a>.
After posting links to these in the lab Slack I got some questions that
forced me to do some thinking. Why not undersample the majority class?</p>
<div id="possibly-a-motivation" class="section level2">
<h2>Possibly a motivation</h2>
<p>So the argument for balancing unbalanced classes seems to stem from the use of
classification accuracy (= fraction predictions where the predicted class was correct) to
evaluate classifiers:
if <span class="math inline">\(.01\)</span> of my observations are <code>True</code>s, I’d get a <span class="math inline">\(.99\)</span> accuracy by always
classifying as <code>False</code>. Since “everything is <code>False</code>” isn’t a very sexy model,
why not make it seem as though there are more <code>True</code>s in the hope that their signal
stands out more clearly against the overwhelming mass of <code>False</code>s?</p>
<p>This tip that you could always try to balance your classes seems to be a piece of
modeling folklore that everyone picks up. The way I pictured it you could just
go ahead and balance your data by either oversampling the minority class or
undersampling the majority class and that would be enough. After looking at
it for this post I’m no longer sure that I trust the balancing of datasets. At
the very least it looks as though you have to do some pos hoc correction for this
balancing act, and it’s probably not always well-defined how to do that.</p>
</div>
<div id="lets-just-try" class="section level2">
<h2>Let’s just try</h2>
<p>I’ll simulate some data from the following logistic model:
<span class="math display">\[ \log \frac{p}{1-p} = \beta_0 + \beta_1x,\]</span>
<span class="math display">\[ X\sim N(0, \sigma),\]</span>
with <span class="math inline">\(\beta_0=9, \beta_1=6,\)</span> and <span class="math inline">\(\sigma=.4\)</span>. This can easily be
transformed into a probability of belonging to <code>True</code>:
<span class="math display">\[p = \frac{1}{1+e^{-(9+6x)}}.\]</span> To generate class labels from probabilities,
draw a uniform number <span class="math inline">\(u\sim U(0,1)\)</span> and assign to <code>True</code>
if <span class="math inline">\(u &lt; p\)</span>. This model gives me about <span class="math inline">\(600 \times\)</span> more <code>False</code>s than <code>True</code>s.
I will generate 100 thousand observations
from this model and fit a logistic regression to i) all the data, ii)
a data set where I have subsampled the <code>False</code>s to get a fake 50-50 split.</p>
<pre class="r"><code>set.seed(07042017)
b_0 &lt;- -9
b_1 &lt;- 6


# simulate data
x &lt;- rnorm(100000, sd=.4)
log_odds &lt;- b_0 + b_1*x
p_y &lt;- 1/(1 + exp(-log_odds))
y &lt;- factor(runif(length(p_y)) &lt;= p_y, levels = c(&quot;FALSE&quot;, &quot;TRUE&quot;))

# class sizes
table(y)</code></pre>
<pre><code>## y
## FALSE  TRUE 
## 99825   175</code></pre>
<pre class="r"><code>table(y)[2]/sum(table(y))</code></pre>
<pre><code>##    TRUE 
## 0.00175</code></pre>
<pre class="r"><code># logistic regression model on full data
glm_fit &lt;- glm(y~x, family=binomial)

# undersample F to get a 50-50 split:
class1 &lt;- which(y==&quot;TRUE&quot;)
class2 &lt;- sample(which(y==&quot;FALSE&quot;), size = length(class1))
pseudosample &lt;- c(class1, class2)

newx &lt;- x[pseudosample]
newy &lt;- y[pseudosample]

# logistic regression on undersampled data
new_glm_fit &lt;- glm(newy~newx, family=binomial)

# compare
lim &lt;- 2
curve(1/(1+exp(-(b_0 + b_1*x))), from = -lim, to = lim, lwd=8, col=&quot;grey&quot;, ylab = &quot;p(True)&quot;, ylim=c(0,1))
curve(1/(1+exp(-(coef(glm_fit)[1] + coef(glm_fit)[2]*x))), lwd=1.5, from = -lim, to = lim, add=T, col=&quot;black&quot;)
curve(1/(1+exp(-(coef(new_glm_fit)[1] + coef(new_glm_fit)[2]*x))), lwd=1.5, from = -lim, to = lim, add=T, col=&quot;red&quot;)
rug(x)</code></pre>
<p><img src="/blog/2017-04-09-undersampling_files/figure-html/all_vs_undersampled-1.png" width="672" /></p>
<p>In the above figure, the thick, grey line is the true model. The black line is
the model estimated from all the data. It’s pretty good. And it’s certainly
not bad enough to make me balk at unbalanced data. The red line is from
undersampling the <code>False</code>s to get an artificial 50-50 split. We see that we
overestimate the probability of <code>True</code> a lot. It doesn’t look like a super
useful model. Clearly the proportion of <code>True</code>s in the population matters
and we just threw it away.</p>
<p>If we wanted to do classification we’d choose some probability threshold
above which we’d assign everything to <code>True</code>. The standard, theoretically best
threshold is <span class="math inline">\(p=.5\)</span>. If we use this threshold under the correct model we will
nearly always classify as <code>False</code>. That’s not bad, <em>that’s the correct
decision.</em> If we use this threshold under the clearly wrong undersampled model we’d
get more predictions of <code>True</code>. Most of them would be wrong.</p>
</div>
<div id="what-happened" class="section level2">
<h2>What happened?</h2>
<p>Let’s do the above exercise again. This time I will do a nonparametric
regression instead of logistic regression. Specifically I want to do
Nadaraya–Watson kernel estimation (NWKE). This is helpful in this
discussion because we won’t have to bend our minds around the whole logit space
vs. probability space thing of logistic regression. The NWKE
directly estimates <span class="math inline">\(r(x) = E[Y|X=x]\)</span> by a weighted average of Y around x as
follows: for observation pairs <span class="math inline">\((x_i, y_i), i\in\{1,2,\ldots, n\}\)</span>, let</p>
<p><span class="math display">\[ \hat r(x) = \sum_{i=1}^n w_i(x)y_i, \]</span></p>
<p>where the weight of observation <span class="math inline">\(i\)</span>, <span class="math inline">\(w_i\)</span>, is a function of <span class="math inline">\(x\)</span>. This
is very easy to reason about, it’s an average of all our observations that’s
weighted so that observations closer to <span class="math inline">\(x\)</span> count more. Specifically, the
weight is defined as</p>
<p><span class="math display">\[ w_i(x) = \frac{K(\frac{x-x_i}{h})}{\sum_{j=1}^n K(\frac{x-x_j}{h})}. \]</span></p>
<p>The function <span class="math inline">\(K\)</span> is a kernel. For our discussion it’s a normal
distribution centered on <span class="math inline">\(x\)</span>. The bandwidth <span class="math inline">\(h\)</span> controls the amount of influence
points far away from x should have. For our discussion it’s the standard
deviation of our normal distribution. The weights clearly sum to 1 and they’re
never negative.</p>
<pre class="r"><code>plot(x, jitter(as.numeric(y)),ylim=c(0.5,4.5), xlim=c(-2, 2), col=&quot;grey&quot;, ylab=&quot;&quot;, yaxt=&quot;n&quot;)
points(newx, jitter(as.numeric(newy)+2), col=&quot;grey&quot;)
lines(ksmooth(x, as.numeric(y), &quot;normal&quot;, bandwidth = .25), lwd=1.5)
lines(ksmooth(newx, as.numeric(newy)+2, &quot;normal&quot;, bandwidth = .5), lwd=1.5) # less data, more smoothing</code></pre>
<p><img src="/blog/2017-04-09-undersampling_files/figure-html/kernel_regression-1.png" width="672" /></p>
<p>Above I have put the full data and the undersampled data in the
same figure along with their NWKE regressions. The <span class="math inline">\(y\)</span> values are jittered,
they are really just zeros and ones. The top pair of clouds is the undersampled data and
the bottom pair is the full data. These regressions look a lot like our logistic
regressions from before. As before, the regression from the undersampled data greatly
overestimates the probability of <code>True</code>. Considering the form of the NWKE it
shouldn’t be too surprising: the estimate at <span class="math inline">\(x\)</span> is <span class="math inline">\(\sum w_i(x)y_i\)</span>, and if you remove a
bunch of the <span class="math inline">\(y_i=0\)</span>, naturally the estimate at <span class="math inline">\(x\)</span> will be larger.
This is basically what’s happening with the logistic
regression as well: there will be too few <span class="math inline">\((\hat r(x) - 0)^2\)</span> terms in the sum of
squares that’s optimized. This works both ways, you’re no better off
oversampling <code>True</code>s, you will be introducing a bunch of <span class="math inline">\(1\)</span>s to inflate the estimate.</p>
</div>
<div id="posterior-correction" class="section level2">
<h2>Posterior correction</h2>
<p>In fact, in logistic regression you get the right odds ratio anyway:
you estimate the slope, <span class="math inline">\(\beta_1\)</span>, correctly in spite of having the wrong proportion of
<code>True</code>s. You can see this in the figure, the estimated curve looks good but for
the fact that it’s shifted way to the left. It’s posible to correct the intercept
<span class="math inline">\(\beta_0\)</span> post hoc. This correction is <span class="math inline">\(\hat \beta_0^* = \hat \beta_0 - \log(\frac{1-\tau}{\tau}\frac{\bar y}{1-\bar y})\)</span>, where <span class="math inline">\(\tau\)</span> is the proportion of <code>True</code>s in the population,
and <span class="math inline">\(\bar y\)</span> is the proportion of <code>True</code>s in your sample. I have this
from King and Zeng <em>Logistic regression in rare events data.</em> Below I apply this
correction to our bad model from earlier:</p>
<pre class="r"><code>tau &lt;- table(y)[2]/sum(table(y))
b_0_corrected &lt;- coef(new_glm_fit)[1] - log((1-tau)/tau)
lim &lt;- 2
curve(1/(1+exp(-(b_0 + b_1*x))), from = -lim, to = lim, lwd=8, col=&quot;grey&quot;, ylab = &quot;p(True)&quot;, ylim=c(0,1))
curve(1/(1+exp(-(coef(glm_fit)[1] + coef(glm_fit)[2]*x))),lwd=1.5, from = -lim, to = lim, add=T, col=&quot;black&quot;)
curve(1/(1+exp(-(b_0_corrected + coef(new_glm_fit)[2]*x))), lwd=1.5, from = -lim, to = lim, add=T, col=&quot;red&quot;)
rug(x)</code></pre>
<p><img src="/blog/2017-04-09-undersampling_files/figure-html/posterior_adjustment-1.png" width="672" /></p>
<p>In spite of this clever correction the undersampled estimate is off. It still
overestimates p(<code>True</code>). In fact, the correction is consistent and its derivation is
surprisingly simple. The estimate is worse because we threw away most of our
data to make it.</p>
<p>Sure, this is a kind of ridiculous example. I’m sure no one would throw away 99 thousand
perfectly fine samples because they worry about imbalanced data, but class
balancing is a thing that people do and it’s interesting to see what the implications are. As
with the logistic regression I’m sure there is some sort of post hoc correction
procedure for class balancing in many methods.</p>
<p>Maybe this stuff works if you’re doing something like the SVM where you
basically look at the shapes of the <code>True</code>s and the <code>False</code>s in euclidean space.
I don’t know. Looking at the NWKE figure above I wouldn’t be too optimistic; we
end up mussing a lot of <code>False</code>s in the critical region around
<span class="math inline">\(x=.5\)</span>. Presumably the separating hyperplane would hence be (wrongy) pushed
toward the <code>False</code>s. The SVM is a pure classification algorithm and as such
intrinsically linked to the classification accuracy scoring rule. If you want a
probability output you end up jury-rigging one by putting the distance to the
separating plane into some sort of function at which point why not just
estimate the probabilities directly to begin with and save yourself the grief?</p>
</div>
<div id="is-this-ever-useful" class="section level2">
<h2>Is this ever useful?</h2>
<p>Sure. In the case of logistic regression where the correction for undersampling
is straight-forward and theoretically sound, it could be useful. But the reasons
I can come up with aren’t because it’s inherently better with artificial Balanced
Data.</p>
<p>I can come up with two interesting cases. First, if you can’t fit your
data in main memory or something, and you’re comfortable with getting a less
exact model, go right ahead.</p>
<p>Second, and perhaps more interesting, is an example from the world of
epidemiology and other places where case–control studies happen. Diseases are
as common as they are, they usually happen to a small fraction of all people and
you can’t very well go out and create more cases. But! You can get as many healthy
controls as you can afford. Hence you can use extra controls to bolster your
estimates for the non-intercept coefficients and, if you know the prevalence of
disease in the population, you can simply adjust the intercept. That’s
pretty handy.</p>
<p>I don’t think I’d generally recommend people throw away their precious data,
however. Though maybe you know something I don’t.</p>
</div>

  </div>
</section>
<section id="tag-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-right meta">
      
      
      
      TAGS:
      
      
      <a class="meta" href="/tags/classification">CLASSIFICATION</a>, 
      
      <a class="meta" href="/tags/logistic-regression">LOGISTIC REGRESSION</a>, 
      
      <a class="meta" href="/tags/prediction">PREDICTION</a>, 
      
      <a class="meta" href="/tags/simulation">SIMULATION</a>, 
      
      <a class="meta" href="/tags/undersampling">UNDERSAMPLING</a>
      
      
      
    </h6>
  </div>
  
</section>








<section id="menu-pane" class="row menu text-center">
  
  
  <span><a class="menu-item" href="http://3inar.github.io/blog/2016-10-03-violence/">&lt; prev | </a></span>
  
  
  <span><a class="menu-item" href="/blog">blog</a></span>
  
  
  <span><a class="menu-item" href="http://3inar.github.io/blog/2017-08-24-auc-harmful/"> | next &gt;</a></span>
  
  
  <h4 class="text-center"><a class="menu-item" href="http://3inar.github.io/">home</a></h4>
</section>



<footer class="row text-center footer">
  <hr />
  
  <h6 class="text-center copyright"></h6>
  
  <h6 class="text-center powered">Powered by <a href="https://gohugo.io/">Hugo</a> &amp; <a href="https://github.com/shenoybr/hugo-goa">Goa</a>.</h6>
  
  
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  

<script type="text/javascript">
hljs.initHighlightingOnLoad();
</script>




<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="js/main.js"></script>
</body>
</html>


