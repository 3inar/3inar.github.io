<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on Just data things</title>
    <link>https://3inar.github.io/blog/</link>
    <description>Recent content in Blogs on Just data things</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© {year}</copyright>
    <lastBuildDate>Tue, 01 Jun 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://3inar.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Note: Bayes false discovery rate</title>
      <link>https://3inar.github.io/blog/2021-06-01-bayes_fdr/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2021-06-01-bayes_fdr/</guid>
      <description>This is a note to section 2.2 in Brad Efron’s book Large-Scale Inference, which I am very slowly working my way through.
In a large-scale -omic experiment we’re calculating thousands of \(Z_i = \frac{\mu_i}{\sigma_i/\sqrt{N}},\)1 where the number of observations, \(N,\) is likely below 100. Let’s say we’re working with gene expression: we use these statistics to evaluate the hypothesis that gene \(i\) is differentially expressed between two groups of interest.</description>
    </item>
    
    <item>
      <title>Stirglin&#39;s approximation [sic]</title>
      <link>https://3inar.github.io/blog/2021-05-13-stirglin/</link>
      <pubDate>Thu, 13 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2021-05-13-stirglin/</guid>
      <description>If you have read any introductory probability material, which I have lately, you have seen Stirling’s approximation to the factorial \[n! = n\cdot(n-1)\cdot(n-2)\cdot\ldots\cdot2\cdot1.\] It seems to be standard material and looks like \[ n! \approx n^ne^{-n}\sqrt{2\pi n} = \hat n!. \]
I introduce the probably nonstandard \(\hat n!\) as a shorthand for this approximation. At the intro to probability level \(\hat n!\) is usually presented without comment. There are various proofs/derivations that show that for large \(n\) the ratio \(\frac{\hat n!</description>
    </item>
    
    <item>
      <title>This delightful book review</title>
      <link>https://3inar.github.io/blog/2020-12-11-lindley-book-rview/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2020-12-11-lindley-book-rview/</guid>
      <description>Please click through for Lindley’s delightful review of Taleb’s book Black Swan..</description>
    </item>
    
    <item>
      <title>A fistful of ducats</title>
      <link>https://3inar.github.io/blog/2020-30-11-utils/</link>
      <pubDate>Mon, 30 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2020-30-11-utils/</guid>
      <description>Some notes on utility and insurance. The below is apropos of ET Jaynes’ Probability Theory, Chapter 13. It’s a useful and interesting book, but Jaynes was apparently no great believer in graphical illustrations.
Utility functions Daniel Bernoulli, one of the many Bernoullis, conceived a utility function \(u(x) \propto log(x)\) in contrast to the linear \(u(x) \propto x\), usual at the time. Naturally \(x\) denotes money: Gambling was the principal object of probability arguments in the mid-1700s.</description>
    </item>
    
    <item>
      <title>Comparing a relative risk to an odds ratio</title>
      <link>https://3inar.github.io/blog/2018-04-22-odds-ratios/</link>
      <pubDate>Sun, 22 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2018-04-22-odds-ratios/</guid>
      <description>In connection with a meta analysis I helped with recently we wanted to compare some relative risk results from another analysis with the odds ratios that came from ours. This made me wonder to what extent the two measurements are comparable. The short story is that they aren’t generally comparable, but when dealing with small probabilities they are quite similar. The long story follows below.
Definitions Suppose we are comparing the probability of falling ill between two groups.</description>
    </item>
    
    <item>
      <title>Changing website framework from Jekyll to Hugo</title>
      <link>https://3inar.github.io/blog/2018-01-24-hugo/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2018-01-24-hugo/</guid>
      <description>I decided to move away from Jekyll as a framework for running this website as I had some gemfile problems (now ruby doesn’t work at all for arcane reasons) and I figured it would be saner, simpler, and faster to just stop using something ruby-based. The switch to Hugo took a couple of hours where most of it went into (i) picking a theme and (ii) making sure the blog posts still work.</description>
    </item>
    
    <item>
      <title>Quick-and-dirty image segmentation</title>
      <link>https://3inar.github.io/blog/2018-01-15-segmentation/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2018-01-15-segmentation/</guid>
      <description>A member of our lab does handwritten digit recognition in a highly structured setting. Without going into details, we want to read images of three-digit handwritten codes and recognize which number the image depicts. To avoid having to predict one of a thousand classes, we want to to split the images into three single digits.
I’m sure there are some very fancy ways indeed of doing this, but the following structure makes me think we can start with simpler solutions: (i) There are always three digits.</description>
    </item>
    
    <item>
      <title>AUC and accuracy considered harmful to model selection</title>
      <link>https://3inar.github.io/blog/2017-08-24-auc-harmful/</link>
      <pubDate>Thu, 24 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2017-08-24-auc-harmful/</guid>
      <description>This post had bugs that messed with my build process and I can’t be bothered fixing it.</description>
    </item>
    
    <item>
      <title>Understanding undersampling</title>
      <link>https://3inar.github.io/blog/2017-04-09-undersampling/</link>
      <pubDate>Sun, 09 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2017-04-09-undersampling/</guid>
      <description>I really like Frank Harrell’s blog. He writes all kinds of useful things, and as I am working in the classification/predition area I was particularly interested in his two posts about classification vs. prediction and improper scoring rules. After posting links to these in the lab Slack I got some questions that forced me to do some thinking. Why not undersample the majority class?
Possibly a motivation So the argument for balancing unbalanced classes seems to stem from the use of classification accuracy (= fraction predictions where the predicted class was correct) to evaluate classifiers: if \(.</description>
    </item>
    
    <item>
      <title>Most violent show on earth</title>
      <link>https://3inar.github.io/blog/2016-10-03-violence/</link>
      <pubDate>Mon, 03 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2016-10-03-violence/</guid>
      <description>Update December, 2020: This post was too much hassle to maintain: its build would break every now and again with updates from the Central Bureau of Statistics. If you want this analysis I point you to the article I wrote with Vittorio Perduca and its GitHub repo</description>
    </item>
    
    <item>
      <title>Neural network overengineering</title>
      <link>https://3inar.github.io/blog/2016-08-24-neural-network-overengineering/</link>
      <pubDate>Wed, 24 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://3inar.github.io/blog/2016-08-24-neural-network-overengineering/</guid>
      <description>In my idle hours (ie when I should have been writing a paper), I came across this blog post where the author trained a neural netwok in the fine art of wine tasting. I am basically deep down a very lazy person, and from what little I understand of NNs, there are quite a few knobs to fiddle with, which really who has the time with all this untasted wine floating about?</description>
    </item>
    
  </channel>
</rss>
